{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import modules\nimport os\nimport pickle\nimport numpy as np\nfrom tqdm.notebook import tqdm\n\nfrom tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow.keras.layers import Input, Dense, LSTM,Embedding,Dropout, add","metadata":{"execution":{"iopub.status.busy":"2023-10-28T14:09:18.176804Z","iopub.execute_input":"2023-10-28T14:09:18.177156Z","iopub.status.idle":"2023-10-28T14:09:18.185311Z","shell.execute_reply.started":"2023-10-28T14:09:18.177112Z","shell.execute_reply":"2023-10-28T14:09:18.184567Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#LOAD VGG16\nmodel=VGG16()\nmodel=Model(inputs=model.inputs, outputs=model.layers[-2].output)\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2023-10-28T14:09:31.827641Z","iopub.execute_input":"2023-10-28T14:09:31.828051Z","iopub.status.idle":"2023-10-28T14:09:37.738020Z","shell.execute_reply.started":"2023-10-28T14:09:31.828021Z","shell.execute_reply":"2023-10-28T14:09:37.737028Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n553467096/553467096 [==============================] - 4s 0us/step\nModel: \"model_1\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n input_7 (InputLayer)        [(None, 224, 224, 3)]     0         \n                                                                 \n block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n                                                                 \n block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n                                                                 \n block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n                                                                 \n block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n                                                                 \n block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n                                                                 \n block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n                                                                 \n block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n                                                                 \n block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n                                                                 \n block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n                                                                 \n block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n                                                                 \n block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n                                                                 \n block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n                                                                 \n block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n                                                                 \n block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n                                                                 \n flatten (Flatten)           (None, 25088)             0         \n                                                                 \n fc1 (Dense)                 (None, 4096)              102764544 \n                                                                 \n fc2 (Dense)                 (None, 4096)              16781312  \n                                                                 \n=================================================================\nTotal params: 134,260,544\nTrainable params: 134,260,544\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"##extraction\n\nfeatures={}\ndirectory='/kaggle/input/muzzle-pics/muzzle_only'\n\nfor img_name in tqdm(os.listdir(directory)):\n    img_path= directory+'/'+ img_name\n    img=load_img(img_path,target_size=(224,224))\n    img=img_to_array(img)\n    img=img.reshape(1,img.shape[0],img.shape[1],img.shape[2])\n    img=preprocess_input(img)\n    feature=model.predict(img,verbose=0)\n    image_id=img_name.split('.')[0]\n    #store features\n    features[image_id]=feature","metadata":{"execution":{"iopub.status.busy":"2023-10-28T14:15:46.951110Z","iopub.execute_input":"2023-10-28T14:15:46.951477Z","iopub.status.idle":"2023-10-28T14:15:49.904513Z","shell.execute_reply.started":"2023-10-28T14:15:46.951450Z","shell.execute_reply":"2023-10-28T14:15:49.903398Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/31 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a8044fb5a24447980e28873056d6864"}},"metadata":{}}]},{"cell_type":"code","source":"WORKING_DIR='/kaggle/working/'\n#storing features in pickle\npickle.dump(features,open(os.path.join(WORKING_DIR,'features.pkl'),'wb'))","metadata":{"execution":{"iopub.status.busy":"2023-10-28T14:16:44.551523Z","iopub.execute_input":"2023-10-28T14:16:44.551932Z","iopub.status.idle":"2023-10-28T14:16:44.558250Z","shell.execute_reply.started":"2023-10-28T14:16:44.551900Z","shell.execute_reply":"2023-10-28T14:16:44.557118Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity  # You can use cosine similarity for feature comparison\n\n# Load the pre-extracted features from the pickle file\nWORKING_DIR = '/kaggle/working/'\nfeatures = pickle.load(open(os.path.join(WORKING_DIR, 'features.pkl'), 'rb'))\n\n# Function to extract features from a new image\ndef extract_features_from_new_image(image_path):\n    img = load_img(image_path, target_size=(224, 224))\n    img = img_to_array(img)\n    img = img.reshape(1, img.shape[0], img.shape[1], img.shape[2])\n    img = preprocess_input(img)\n    feature = model.predict(img, verbose=0)\n    return feature\n\n# Path to the new image you want to compare\nnew_image_path = '/kaggle/input/test-imgs/test dataset/C.png'\n\n# Extract features from the new image\nnew_image_features = extract_features_from_new_image(new_image_path)\n\n# Initialize variables to track the best match and similarity\n#best_match = None\nbest_similarity = 0.0\n\n# Compare the new image features with features in the dataset\nfor image_id, dataset_feature in features.items():\n    # Calculate the cosine similarity between the new image features and dataset features\n    similarity = cosine_similarity(new_image_features, dataset_feature)\n    \n    if similarity > best_similarity:\n        best_similarity = similarity\n        #best_match = image_id\n\n# Set a similarity threshold (you can adjust this)\nsimilarity_threshold = 0.9\n\nif best_similarity > similarity_threshold:\n    print(\"match found.\")\nelse:\n    print(\"No match found.\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-28T14:24:56.646617Z","iopub.execute_input":"2023-10-28T14:24:56.647027Z","iopub.status.idle":"2023-10-28T14:24:56.772408Z","shell.execute_reply.started":"2023-10-28T14:24:56.646995Z","shell.execute_reply":"2023-10-28T14:24:56.771422Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"No match found.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
